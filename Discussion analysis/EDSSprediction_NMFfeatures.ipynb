{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAAIMS \n",
    "### EDSS prediction analysis on the reduced 2 NMF regress-N features for revision of paper: We do binary classification with groups Mild vs Moderate with EDSS 1-4.5 vs 5-6 respectively. \n",
    "#### Rachneet Kaur \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import os\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn import decomposition\n",
    "\n",
    "import xgboost \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from inspect import signature\n",
    "from scipy import interp\n",
    "from pyitlib import discrete_random_variable as drv\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\purpl\\\\Box\\\\GAIT\\\\sample_data\\\\data_export\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regress-N data shape:  (3230, 25)\n"
     ]
    }
   ],
   "source": [
    "#Reading the Regress-N dataframe \n",
    "regressN_df = pd.read_csv(path+'..\\\\..\\\\FinalCodes\\\\csv files\\\\mr_scaled_features_30controlsTrialW.csv', index_col = 0)\n",
    "regressN_df.reset_index(inplace= True)\n",
    "print('Regress-N data shape: ', regressN_df.shape)\n",
    "\n",
    "#Delete the treadmill speeds as features since they are very very correlated with stride speed\n",
    "#Also delete Butterfly plot y-direction features since COP_Y is not adjusted \n",
    "#Swing time and SS_L are the same\n",
    "to_drop = ['tspeed_HSR', 'tspeed_MidSSR', 'tspeed_TOR', 'tspeed_HSL', 'tspeed_TOL', 'tspeed_MidSSL',  'Butterfly_y_abs', \n",
    "           'ButterflySQ_y', 'SS_L', 'index']\n",
    "regressN_df.drop(['index'], axis = 1, inplace = True)\n",
    "regressN_df = regressN_df[regressN_df['Label']==1] #Keeping only PwMS\n",
    "\n",
    "#Reading the EDSS scores for PwMS \n",
    "edss= pd.read_csv('..//edss.csv')\n",
    "#Keeping edss of only the 17 PwMS subjects we have the raw data for \n",
    "edss = edss[edss['PID'].isin(regressN_df[regressN_df['Label']==1]['PID'].unique())].reset_index().drop('index', axis =1)\n",
    "\n",
    "#Attaching the EDSS to the dataframe\n",
    "regressN_df['edss'] = regressN_df['PID'].map(edss.set_index('PID')['EDSS'])\n",
    "\n",
    "#Creating the new labels for mild (EDSS 1-4.5) vs moderate (EDSS 5-6)\n",
    "regressN_df['Label'][regressN_df['edss']<=4.5] = 0 #0 for mild \n",
    "regressN_df['Label'][regressN_df['edss']>=5] = 1 #1 for moderate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['stride_time', 'stance_time', 'swing_time', 'SS_R', 'DS_R', 'DS_L', 'cadence', 'stride_length', 'stride_width',\n",
    "       'LeftFPA', 'RightFPA', 'stride_speed',  'walk_ratio', 'force_HSR', 'force_TOL', 'force_MidSSR',\n",
    "       'force_HSL', 'force_TOR', 'force_MidSSL','Butterfly_x_abs', 'ButterflySQ_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stride_time</th>\n",
       "      <th>swing_time</th>\n",
       "      <th>stance_time</th>\n",
       "      <th>SS_R</th>\n",
       "      <th>DS_L</th>\n",
       "      <th>DS_R</th>\n",
       "      <th>stride_length</th>\n",
       "      <th>stride_width</th>\n",
       "      <th>cadence</th>\n",
       "      <th>stride_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>force_TOL</th>\n",
       "      <th>force_MidSSL</th>\n",
       "      <th>LeftFPA</th>\n",
       "      <th>RightFPA</th>\n",
       "      <th>Butterfly_x_abs</th>\n",
       "      <th>ButterflySQ_x</th>\n",
       "      <th>PID</th>\n",
       "      <th>TrialID</th>\n",
       "      <th>Label</th>\n",
       "      <th>edss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1.427284</td>\n",
       "      <td>0.825449</td>\n",
       "      <td>1.698498</td>\n",
       "      <td>1.451010</td>\n",
       "      <td>2.275607</td>\n",
       "      <td>1.591079</td>\n",
       "      <td>0.356788</td>\n",
       "      <td>1.603865</td>\n",
       "      <td>0.693365</td>\n",
       "      <td>0.247979</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023453</td>\n",
       "      <td>1.144372</td>\n",
       "      <td>-17.906300</td>\n",
       "      <td>-81.365486</td>\n",
       "      <td>0.093181</td>\n",
       "      <td>0.553099</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>1.364776</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>1.555251</td>\n",
       "      <td>1.173380</td>\n",
       "      <td>2.117304</td>\n",
       "      <td>1.722825</td>\n",
       "      <td>0.366358</td>\n",
       "      <td>1.933280</td>\n",
       "      <td>0.725122</td>\n",
       "      <td>0.266292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947790</td>\n",
       "      <td>1.111496</td>\n",
       "      <td>16.643585</td>\n",
       "      <td>-71.453487</td>\n",
       "      <td>0.987034</td>\n",
       "      <td>1.937089</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>1.548829</td>\n",
       "      <td>1.097116</td>\n",
       "      <td>1.744542</td>\n",
       "      <td>1.058137</td>\n",
       "      <td>2.127198</td>\n",
       "      <td>2.685580</td>\n",
       "      <td>0.459438</td>\n",
       "      <td>1.783671</td>\n",
       "      <td>0.638953</td>\n",
       "      <td>0.294265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>1.153409</td>\n",
       "      <td>-39.773788</td>\n",
       "      <td>307.247234</td>\n",
       "      <td>5.521313</td>\n",
       "      <td>11.069417</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>1.310949</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>1.506650</td>\n",
       "      <td>0.948133</td>\n",
       "      <td>2.067834</td>\n",
       "      <td>2.016719</td>\n",
       "      <td>0.417583</td>\n",
       "      <td>1.776315</td>\n",
       "      <td>0.754895</td>\n",
       "      <td>0.315989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006676</td>\n",
       "      <td>1.128446</td>\n",
       "      <td>25.850804</td>\n",
       "      <td>-221.182818</td>\n",
       "      <td>4.942584</td>\n",
       "      <td>8.453359</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1.343939</td>\n",
       "      <td>0.867244</td>\n",
       "      <td>1.555251</td>\n",
       "      <td>0.916703</td>\n",
       "      <td>1.771016</td>\n",
       "      <td>2.574103</td>\n",
       "      <td>0.446703</td>\n",
       "      <td>1.793104</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.329727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>1.128360</td>\n",
       "      <td>-8.629545</td>\n",
       "      <td>44.172824</td>\n",
       "      <td>5.981351</td>\n",
       "      <td>13.400158</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>0.874860</td>\n",
       "      <td>0.960934</td>\n",
       "      <td>0.808321</td>\n",
       "      <td>0.969086</td>\n",
       "      <td>0.666459</td>\n",
       "      <td>0.669519</td>\n",
       "      <td>1.128300</td>\n",
       "      <td>1.200901</td>\n",
       "      <td>1.130886</td>\n",
       "      <td>1.297014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996007</td>\n",
       "      <td>0.917539</td>\n",
       "      <td>2.168443</td>\n",
       "      <td>20.954078</td>\n",
       "      <td>1.032380</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>0.866059</td>\n",
       "      <td>0.923771</td>\n",
       "      <td>0.813437</td>\n",
       "      <td>0.969086</td>\n",
       "      <td>0.706851</td>\n",
       "      <td>0.648918</td>\n",
       "      <td>1.120058</td>\n",
       "      <td>1.132558</td>\n",
       "      <td>1.142379</td>\n",
       "      <td>1.300624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007720</td>\n",
       "      <td>0.879937</td>\n",
       "      <td>-2.028938</td>\n",
       "      <td>-9.061530</td>\n",
       "      <td>1.067982</td>\n",
       "      <td>0.808281</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>0.878381</td>\n",
       "      <td>0.923771</td>\n",
       "      <td>0.831343</td>\n",
       "      <td>0.942894</td>\n",
       "      <td>0.757340</td>\n",
       "      <td>0.721020</td>\n",
       "      <td>0.985845</td>\n",
       "      <td>1.319821</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>1.128716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985558</td>\n",
       "      <td>0.955371</td>\n",
       "      <td>1.996335</td>\n",
       "      <td>3.882285</td>\n",
       "      <td>4.415241</td>\n",
       "      <td>10.551841</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>0.903025</td>\n",
       "      <td>0.955625</td>\n",
       "      <td>0.851807</td>\n",
       "      <td>0.932418</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>0.751921</td>\n",
       "      <td>0.932572</td>\n",
       "      <td>1.450322</td>\n",
       "      <td>1.095615</td>\n",
       "      <td>1.038582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956524</td>\n",
       "      <td>0.995181</td>\n",
       "      <td>5.303354</td>\n",
       "      <td>-5.496849</td>\n",
       "      <td>4.460976</td>\n",
       "      <td>10.761418</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>0.973436</td>\n",
       "      <td>1.088351</td>\n",
       "      <td>0.890177</td>\n",
       "      <td>0.921941</td>\n",
       "      <td>0.918906</td>\n",
       "      <td>0.834323</td>\n",
       "      <td>0.885141</td>\n",
       "      <td>1.503042</td>\n",
       "      <td>1.016366</td>\n",
       "      <td>0.914458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950344</td>\n",
       "      <td>1.005334</td>\n",
       "      <td>3.067077</td>\n",
       "      <td>9.228541</td>\n",
       "      <td>4.846353</td>\n",
       "      <td>12.609187</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stride_time  swing_time  stance_time      SS_R      DS_L      DS_R  \\\n",
       "905      1.427284    0.825449     1.698498  1.451010  2.275607  1.591079   \n",
       "906      1.364776    0.929937     1.555251  1.173380  2.117304  1.722825   \n",
       "907      1.548829    1.097116     1.744542  1.058137  2.127198  2.685580   \n",
       "908      1.310949    0.867244     1.506650  0.948133  2.067834  2.016719   \n",
       "909      1.343939    0.867244     1.555251  0.916703  1.771016  2.574103   \n",
       "...           ...         ...          ...       ...       ...       ...   \n",
       "3225     0.874860    0.960934     0.808321  0.969086  0.666459  0.669519   \n",
       "3226     0.866059    0.923771     0.813437  0.969086  0.706851  0.648918   \n",
       "3227     0.878381    0.923771     0.831343  0.942894  0.757340  0.721020   \n",
       "3228     0.903025    0.955625     0.851807  0.932418  0.828025  0.751921   \n",
       "3229     0.973436    1.088351     0.890177  0.921941  0.918906  0.834323   \n",
       "\n",
       "      stride_length  stride_width   cadence  stride_speed  ...  force_TOL  \\\n",
       "905        0.356788      1.603865  0.693365      0.247979  ...   1.023453   \n",
       "906        0.366358      1.933280  0.725122      0.266292  ...   0.947790   \n",
       "907        0.459438      1.783671  0.638953      0.294265  ...   0.993012   \n",
       "908        0.417583      1.776315  0.754895      0.315989  ...   1.006676   \n",
       "909        0.446703      1.793104  0.736364      0.329727  ...   0.970183   \n",
       "...             ...           ...       ...           ...  ...        ...   \n",
       "3225       1.128300      1.200901  1.130886      1.297014  ...   0.996007   \n",
       "3226       1.120058      1.132558  1.142379      1.300624  ...   1.007720   \n",
       "3227       0.985845      1.319821  1.126354      1.128716  ...   0.985558   \n",
       "3228       0.932572      1.450322  1.095615      1.038582  ...   0.956524   \n",
       "3229       0.885141      1.503042  1.016366      0.914458  ...   0.950344   \n",
       "\n",
       "      force_MidSSL    LeftFPA    RightFPA  Butterfly_x_abs  ButterflySQ_x  \\\n",
       "905       1.144372 -17.906300  -81.365486         0.093181       0.553099   \n",
       "906       1.111496  16.643585  -71.453487         0.987034       1.937089   \n",
       "907       1.153409 -39.773788  307.247234         5.521313      11.069417   \n",
       "908       1.128446  25.850804 -221.182818         4.942584       8.453359   \n",
       "909       1.128360  -8.629545   44.172824         5.981351      13.400158   \n",
       "...            ...        ...         ...              ...            ...   \n",
       "3225      0.917539   2.168443   20.954078         1.032380       0.763975   \n",
       "3226      0.879937  -2.028938   -9.061530         1.067982       0.808281   \n",
       "3227      0.955371   1.996335    3.882285         4.415241      10.551841   \n",
       "3228      0.995181   5.303354   -5.496849         4.460976      10.761418   \n",
       "3229      1.005334   3.067077    9.228541         4.846353      12.609187   \n",
       "\n",
       "      PID  TrialID  Label  edss  \n",
       "905   300        1      1   6.0  \n",
       "906   300        1      1   6.0  \n",
       "907   300        1      1   6.0  \n",
       "908   300        1      1   6.0  \n",
       "909   300        1      1   6.0  \n",
       "...   ...      ...    ...   ...  \n",
       "3225  323        2      0   3.0  \n",
       "3226  323        2      0   3.0  \n",
       "3227  323        2      0   3.0  \n",
       "3228  323        2      0   3.0  \n",
       "3229  323        2      0   3.0  \n",
       "\n",
       "[1447 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressN_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do NMF of trials W and WT together for subject generalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the dataset - Only PwMS in trial W\n",
    "dataset_W_WT = regressN_df_normal[(regressN_df['Label']==1)] #RegressN - Trial W #['Label'==1] for see progression on only MS (second plot)\n",
    "\n",
    "#Attaching the EDSS to the corresponding subjects \n",
    "dataset_W_WT['edss'] = regressN_df['PID'].map(edss.set_index('PID')['EDSS'])\n",
    "dataset_W_WT['color'] = 'r' #Initially all red\n",
    "dataset_W['color'][dataset_W[regressN_df['Label']==0].index] = 'g' #Green for controls \n",
    "# dataset['color'][(dataset['edss']>=5) & (dataset['edss']<=6)] = 'r' #Blue for 0 to 4 EDSS score\n",
    "# # dataset['color'][(dataset['edss']>=3.5) & (dataset['edss']<5)] = 'b' #Blue for 0 to 4 EDSS score\n",
    "\n",
    "prog_data_W_WT = dataset_W.drop(['color', 'edss'], axis =1)\n",
    "\n",
    "#Linear methods: NMF/PCA/ICA\n",
    "# NMF\n",
    "model_NMF_W_WT = decomposition.NMF(n_components=2, init='nndsvda', max_iter=500)\n",
    "# model_NMF3 = decomposition.NMF(n_components=3, init='nndsvda', max_iter=200)\n",
    "NMF_2D_W_WT = model_NMF_W_WT.fit_transform(prog_data_W_WT)\n",
    "# NMF_3D = model_NMF3.fit_transform(prog_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task generalization \n",
    "#### Now, we need to first normalize between 0 and 1 and then fit and tranform using an NMF to get 2 features which we shuffle and then use the ones with trial W in training and ones with trial WT in testing. Note that we cannot normalize or do NMF on trial W (training set) and trails WT (testing set) separately because, the resultant vectors from train and test NMFs will have different directions (due to unequal variance). Due to this, we’ll end up comparing data registered on different axes. Therefore, the resulting vectors from train and test data should have same axes.\n",
    "##### Refer https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/\n",
    "#### Also, we cannot not combine the train (trials W) and test set (trials WT) to obtain NMF components of whole data at once. Because, this would violate the entire assumption of generalization since test data would get 'leaked' into the training set. In other words, the test data set would no longer remain 'unseen'. Eventually, this will hammer down the generalization capability of the model.\n",
    "### Hence, for task generalization, we derive the normalization parameters on the training set (trials W) and then use the same parameters to normalize the test set (trials WT). Similarly, for NMF, we fit the 2D NMF on training set (trials W) and then tranform using the fitted NMF both the training (trials W) and the test set (i.e. trials WT). This way, neither we fit NMF on both training and test set separately nor do we mix them and then do NMF together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data before ML methods \n",
    "#Take care that testing set is not used while normalizaing the training set, otherwise the train set indirectly contains \n",
    "#information about the test set\n",
    "def normalize(dataframe, n_type): \n",
    "    '''\n",
    "    Input: dataframe, type of normalization (z-score or min-max)\n",
    "    '''\n",
    "    col_names = list(dataframe.columns)\n",
    "    if (n_type == 'z'): #z-score normalization \n",
    "        mean = dataframe.mean()\n",
    "        sd = dataframe.std()\n",
    "    else: #min-max normalization\n",
    "        mean = dataframe.min()\n",
    "        sd = dataframe.max()-dataframe.min()\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, trueY):\n",
    "    test_labels = trueY['Label'] #Dropping the PID\n",
    "    predictions = model.predict(test_features)\n",
    "    try:\n",
    "        prediction_prob = model.predict_proba(test_features)[:, 1] #Score of the class with greater label\n",
    "    except:\n",
    "        prediction_prob = model.best_estimator_._predict_proba_lr(test_features)[:, 1] #For linear SVM \n",
    "    #Stride wise metrics \n",
    "    acc = accuracy_score(test_labels, predictions)\n",
    "    p = precision_score(test_labels, predictions)\n",
    "    r = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    auc = roc_auc_score(test_labels, prediction_prob)\n",
    "    print('Stride-based model performance: ', acc, p, r, f1, auc)\n",
    "    \n",
    "    #For computing person wise metrics \n",
    "    temp = copy.deepcopy(trueY) #True label for the stride \n",
    "    temp['pred'] = predictions #Predicted label for the stride \n",
    "    #Correctly slassified strides i.e. 1 if stride is correctly classified and 0 if otherwise\n",
    "    temp['correct'] = (temp['Label']==temp['pred'])\n",
    "\n",
    "    #Proportion of correctly classified strides\n",
    "    proportion_strides_correct = temp.groupby('PID').aggregate({'correct': 'mean'})  \n",
    "    proportion_strides_correct['True Label'] = regressN_testY.groupby('PID').first() \n",
    "\n",
    "    #Label for the person - 0=healthy, 1=MS patient\n",
    "    proportion_strides_correct['Predicted Label'] = proportion_strides_correct['True Label']*\\\n",
    "    (proportion_strides_correct['correct']>0.5)+(1-proportion_strides_correct['True Label'])*\\\n",
    "    (proportion_strides_correct['correct']<0.5) \n",
    "\n",
    "    #Probability of class 1 - MS patient for AUC calculation\n",
    "    proportion_strides_correct['prob_class1'] = (1-proportion_strides_correct['True Label'])*\\\n",
    "    (1-proportion_strides_correct['correct'])+ proportion_strides_correct['True Label']*proportion_strides_correct['correct'] \n",
    "    \n",
    "    try:\n",
    "        print (model.best_estimator_)\n",
    "    except:\n",
    "        pass\n",
    "    #Person wise metrics \n",
    "    person_acc = accuracy_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'])\n",
    "    person_p = precision_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'])\n",
    "    person_r = recall_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'])\n",
    "    person_f1 = f1_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'])\n",
    "    person_auc = roc_auc_score(proportion_strides_correct['True Label'], proportion_strides_correct['prob_class1'])\n",
    "    print('Person-based model performance: ', person_acc, person_p, person_r, person_f1, person_auc)\n",
    "    return proportion_strides_correct['prob_class1'], [acc, p, r, f1, auc, person_acc, person_p, person_r, person_f1, person_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(trainX, trainY, testX, testY, model_name = 'random_forest'):\n",
    "    '''\n",
    "    training set: trainX, testX\n",
    "    testing set: testX, testY\n",
    "    model: model_name\n",
    "    '''\n",
    "    trainY1 = trainY['Label'] #Dropping the PID\n",
    "    \n",
    "    if(model_name == 'random_forest'): #Random Forest\n",
    "        grid = {\n",
    "       'n_estimators': [40,45,50],\\\n",
    "       'max_depth' : [15,20,25,None],\\\n",
    "       'class_weight': [None, 'balanced'],\\\n",
    "       'max_features': ['auto','sqrt','log2', None],\\\n",
    "       'min_samples_leaf':[1,2,0.1,0.05]\n",
    "        }\n",
    "        rf_grid = RandomForestClassifier(random_state=0)\n",
    "        grid_search = GridSearchCV(estimator = rf_grid, param_grid = grid, scoring='accuracy', n_jobs = 1, cv = 5)\n",
    "    \n",
    "    if(model_name == 'adaboost'): #Adaboost\n",
    "        ada_grid = AdaBoostClassifier(random_state=0)\n",
    "        grid = {\n",
    "        'n_estimators':[50, 75, 100, 125, 150],\\\n",
    "        'learning_rate':[0.01,.1, 1, 1.5, 2]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(ada_grid, param_grid = grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'kernel_svm'): #RBF SVM\n",
    "        svc_grid = SVC(kernel = 'rbf', probability=True, random_state=0)\n",
    "        grid = {\n",
    "        'gamma':[0.0001, 0.001, 0.1, 1, 10, ]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(svc_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "\n",
    "    if(model_name == 'gbm'): #GBM\n",
    "        gbm_grid = GradientBoostingClassifier(random_state=0)\n",
    "        grid = {\n",
    "        'learning_rate':[0.15,0.1,0.05], \\\n",
    "        'n_estimators':[50, 100, 150],\\\n",
    "        'max_depth':[2,4,7],\\\n",
    "        'min_samples_split':[2,4], \\\n",
    "        'min_samples_leaf':[1,3]\n",
    "        }\n",
    "        grid_search = GridSearchCV(gbm_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name=='xgboost'): #Xgboost\n",
    "        xgb_grid = xgboost.XGBClassifier(random_state=0)\n",
    "        grid = {\n",
    "            'min_child_weight': [1, 5],\\\n",
    "            'gamma': [0.1, 0.5, 1, 1.5, 2],\\\n",
    "            'subsample': [0.6, 0.8, 1.0],\\\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\\\n",
    "            'max_depth': [5, 7, 8]\n",
    "        }\n",
    "        grid_search = GridSearchCV(xgb_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'knn'): #KNN\n",
    "        knn_grid = KNeighborsClassifier()\n",
    "        grid = {\n",
    "            'n_neighbors': [1, 3, 4, 5, 10],\\\n",
    "            'p': [1, 2, 3, 4, 5]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(knn_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "        \n",
    "    if(model_name == 'decision_tree'): #Decision Tree\n",
    "        dec_grid = DecisionTreeClassifier(random_state=0)\n",
    "        grid = {\n",
    "            'min_samples_split': range(2, 50),\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(dec_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'linear_svm'): #Linear SVM\n",
    "        lsvm_grid = LinearSVC(random_state=0)\n",
    "        grid = {\n",
    "            'loss': ['hinge','squared_hinge'],\\\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(lsvm_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'logistic_regression'): #Logistic regression\n",
    "        grid_search = LogisticRegression(random_state=0)\n",
    "    \n",
    "    if(model_name == 'mlp'):\n",
    "        mlp_grid = MLPClassifier(activation='relu', solver='adam', learning_rate = 'adaptive', learning_rate_init=0.001,\\\n",
    "                                                        shuffle=False, max_iter = 200, random_state = 0)\n",
    "        grid = {\n",
    "            'hidden_layer_sizes': [(128, 8, 8, 128, 32), (50, 50, 50, 50, 50, 50, 150, 100, 10), \n",
    "                                  (50, 50, 50, 50, 50, 60, 30, 20, 50), (50, 50, 50, 50, 50, 150, 10, 60, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 50, 10, 5), (50, 50, 50, 50, 50, 5, 50, 150, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 30, 50, 20), (50, 50, 50, 50, 10, 150, 20, 20, 30),\n",
    "                                  (50, 50, 50, 50, 30, 150, 100, 20, 100), (50, 50, 50, 50, 30, 5, 100, 20, 100),\n",
    "                                  (50, 50, 50, 50, 60, 50, 50, 60, 60), (50, 50, 50, 50, 20, 50, 60, 20, 20),\n",
    "                                  (50, 50, 50, 10, 50, 10, 150, 60, 150), (50, 50, 50, 10, 50, 150, 30, 150, 5),\n",
    "                                  (50, 50, 50, 10, 50, 20, 150, 5, 10), (50, 50, 50, 10, 150, 50, 20, 20, 100), \n",
    "                                  (50, 50, 50, 30, 100, 5, 30, 150, 30), (50, 50, 50, 50, 100, 150, 100, 200), \n",
    "                                  (50, 50, 50, 5, 5, 100, 100, 150), (50, 50, 5, 50, 200, 100, 150, 5), \n",
    "                                  (50, 50, 5, 5, 200, 100, 50, 30), (50, 50, 5, 10, 5, 200, 200, 10), \n",
    "                                  (50, 50, 5, 30, 5, 5, 50, 10), (50, 50, 5, 200, 50, 5, 5, 50), \n",
    "                                  (50, 50,50, 5, 5, 100, 100, 150), (5, 5, 5, 5, 5, 100, 50, 5, 50, 50), \n",
    "                                  (5, 5, 5, 5, 5, 100, 20, 100, 30, 30), (5, 5, 5, 5, 5, 20, 20, 5, 30, 100), \n",
    "                                  (5, 5, 5, 5, 5, 20, 20, 100, 10, 10), (5, 5, 5, 5, 10, 10, 30, 50, 10, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 30, 30, 30, 10), (5, 5, 5, 5, 10, 100, 50, 10, 50, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 20, 100, 30, 5), (5, 5, 5, 5, 30, 5, 20, 30, 100, 50), \n",
    "                                  (5, 5, 5, 5, 30, 100, 20, 50, 20, 30), (5, 5, 5, 5, 50, 30, 5, 50, 10, 100), \n",
    "                                  (21, 21, 7, 84, 21, 84, 84), (21, 21, 5, 42, 42, 7, 42), (21, 84, 7, 7, 7, 84, 5), \n",
    "                                  (21, 7, 84, 5, 5, 21, 120), (42, 5, 21, 21, 21, 5, 120), (42, 5, 42, 84, 7, 120, 84), \n",
    "                                  (50, 100, 10, 5, 100, 25), (10, 10, 25, 50, 25, 5), (50, 50, 50, 50, 50, 20, 30, 100, 60)]\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(mlp_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "        \n",
    "    grid_search.fit(trainX, trainY1) #Fitting on the training set to find the optimal hyperparameters \n",
    "#     print('best score: ', grid_search.best_score_)\n",
    "#     print('best_params: ', grid_search.best_params_, grid_search.best_index_)\n",
    "#     print('Mean cv accuracy on test set:', grid_search.cv_results_['mean_test_score'][grid_search.best_index_])\n",
    "#     print('Standard deviation on test set:' , grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
    "#     print('Mean cv accuracy on train set:', grid_search.cv_results_['mean_train_score'][grid_search.best_index_])\n",
    "#     print('Standard deviation on train set:', grid_search.cv_results_['std_train_score'][grid_search.best_index_])\n",
    "#     print('Test set performance:\\n')\n",
    "    stride_person_metrics = evaluate(grid_search, testX, testY)\n",
    "    return stride_person_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strides in training set:  749\n",
      "Control strides in training set:  488\n",
      "MS strides in training set:  261\n",
      "Strides in test set:  670\n",
      "Control strides in test set:  468\n",
      "MS strides in test set:  202\n",
      "Imbalance ratio (controls:MS)= 1: 0.43162393162393164\n"
     ]
    }
   ],
   "source": [
    "#Trial W for training \n",
    "regressN_trial1 = regressN_df[regressN_df['TrialID']==1]\n",
    "regressN_trainX = regressN_trial1.drop(['Label', 'PID', 'TrialID', 'edss'], axis = 1)\n",
    "regressN_trainY = regressN_trial1[['PID', 'Label']]\n",
    "\n",
    "#Trial WT for testing \n",
    "regressN_trial2 = regressN_df[regressN_df['TrialID']==2]\n",
    "regressN_testX = regressN_trial2.drop(['Label', 'PID', 'TrialID', 'edss'], axis = 1)\n",
    "regressN_testY = regressN_trial2[['PID', 'Label']] #PID to compute person based metrics later \n",
    "\n",
    "#Normalize according to min-max normalization so that we have all non-negative entries for NMF \n",
    "norm_mean, norm_sd = normalize(regressN_trainX, 'm')\n",
    "regressN_trainX_norm = (regressN_trainX-norm_mean)/norm_sd\n",
    "regressN_testX_norm = (regressN_testX-norm_mean)/norm_sd\n",
    "#Since for NMF, we must ensure non-negativity of features \n",
    "#If after min-max normalization using the training set derived parametrs, some of the test set feature are \n",
    "#negative, we just drop the strides that have negative feature values. Overall, it dropped 28 strides. \n",
    "regressN_testX_norm = regressN_testX_norm[regressN_testX_norm>0].dropna() \n",
    "\n",
    "#If the strides got dropped from the test set, we must drop corresponding labels too from the Y test set \n",
    "regressN_testY = regressN_testY.loc[regressN_testX_norm.index]\n",
    "\n",
    "# NMF\n",
    "model_NMF_W = decomposition.NMF(n_components=2, init='nndsvda', max_iter=500)\n",
    "NMF_2D_W_fit = model_NMF_W.fit(regressN_trainX_norm) #Fit NMF on the normalized training data \n",
    "#Transform both the normalized training and test data using the fitted NMF \n",
    "NMF_2D_W_train_X = NMF_2D_W_fit.transform(regressN_trainX_norm) \n",
    "NMF_2D_W_test_X = NMF_2D_W_fit.transform(regressN_testX_norm) \n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in training set: ', len(regressN_trainY))\n",
    "print ('Control strides in training set: ', len(regressN_trainY)-regressN_trainY['Label'].sum())\n",
    "print('MS strides in training set: ', regressN_trainY['Label'].sum())\n",
    "\n",
    "#Test Set\n",
    "print('Strides in test set: ', len(regressN_testY)) \n",
    "print ('Control strides in test set: ', len(regressN_testY)-regressN_testY['Label'].sum())\n",
    "print('MS strides in test set: ', regressN_testY['Label'].sum())\n",
    "print ('Imbalance ratio (controls:MS)= 1:', regressN_testY['Label'].sum()/(len(regressN_testY)-regressN_testY['Label'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((749, 4), (749, 2))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF_2D_W_train.shape, regressN_trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         NMF1      NMF2  PID  Label\n",
       " 580  0.199230  0.052566  320      0\n",
       " 310  0.184635  0.056117  305      0\n",
       " 14   0.103687  0.147105  300      1\n",
       " 542  0.157105  0.092977  320      0\n",
       " 76   0.244976  0.000000  301      0\n",
       " ..        ...       ...  ...    ...\n",
       " 9    0.077010  0.183971  300      1\n",
       " 359  0.115981  0.143952  306      0\n",
       " 192  0.242726  0.003538  303      0\n",
       " 629  0.168760  0.082765  323      0\n",
       " 559  0.187292  0.059529  320      0\n",
       " \n",
       " [670 rows x 4 columns],\n",
       "       PID  Label\n",
       " 2532  300      1\n",
       " 2533  300      1\n",
       " 2534  300      1\n",
       " 2535  300      1\n",
       " 2536  300      1\n",
       " ...   ...    ...\n",
       " 3225  323      0\n",
       " 3226  323      0\n",
       " 3227  323      0\n",
       " 3228  323      0\n",
       " 3229  323      0\n",
       " \n",
       " [670 rows x 2 columns])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF_2D_W_test, regressN_testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making the dataframes from the NMF and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NMF1</th>\n",
       "      <th>NMF2</th>\n",
       "      <th>PID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.182662</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075213</td>\n",
       "      <td>0.183552</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099717</td>\n",
       "      <td>0.214073</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073731</td>\n",
       "      <td>0.179502</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.189985</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.188795</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.180261</td>\n",
       "      <td>0.061352</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.175497</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.160301</td>\n",
       "      <td>0.102967</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.126572</td>\n",
       "      <td>0.132527</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>749 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NMF1      NMF2  PID  Label\n",
       "0    0.071551  0.182662  300      1\n",
       "1    0.075213  0.183552  300      1\n",
       "2    0.099717  0.214073  300      1\n",
       "3    0.073731  0.179502  300      1\n",
       "4    0.087841  0.189985  300      1\n",
       "..        ...       ...  ...    ...\n",
       "744  0.188795  0.060960  323      0\n",
       "745  0.180261  0.061352  323      0\n",
       "746  0.175497  0.082933  323      0\n",
       "747  0.160301  0.102967  323      0\n",
       "748  0.126572  0.132527  323      0\n",
       "\n",
       "[749 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training data \n",
    "NMF_2D_W_train_X_df = pd.DataFrame(NMF_2D_W_train_X, columns = ['NMF1', 'NMF2'])\n",
    "NMF_2D_W_train = pd.concat((NMF_2D_W_train_X_df, regressN_trainY.reset_index()), axis = 1).drop(['index'], axis = 1)\n",
    "NMF_2D_W_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NMF1</th>\n",
       "      <th>NMF2</th>\n",
       "      <th>PID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070375</td>\n",
       "      <td>0.238629</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061841</td>\n",
       "      <td>0.195086</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095758</td>\n",
       "      <td>0.215435</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077801</td>\n",
       "      <td>0.200282</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071030</td>\n",
       "      <td>0.200948</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.202263</td>\n",
       "      <td>0.047098</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.200874</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.182430</td>\n",
       "      <td>0.073206</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.174135</td>\n",
       "      <td>0.075527</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.164522</td>\n",
       "      <td>0.089303</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NMF1      NMF2  PID  Label\n",
       "0    0.070375  0.238629  300      1\n",
       "1    0.061841  0.195086  300      1\n",
       "2    0.095758  0.215435  300      1\n",
       "3    0.077801  0.200282  300      1\n",
       "4    0.071030  0.200948  300      1\n",
       "..        ...       ...  ...    ...\n",
       "665  0.202263  0.047098  323      0\n",
       "666  0.200874  0.041536  323      0\n",
       "667  0.182430  0.073206  323      0\n",
       "668  0.174135  0.075527  323      0\n",
       "669  0.164522  0.089303  323      0\n",
       "\n",
       "[670 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test data \n",
    "NMF_2D_W_test_X_df = pd.DataFrame(NMF_2D_W_test_X, columns = ['NMF1', 'NMF2'])\n",
    "NMF_2D_W_test = pd.concat((NMF_2D_W_test_X_df, regressN_testY.reset_index()), axis = 1).drop(['index'], axis = 1)\n",
    "NMF_2D_W_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NMF1      NMF2  PID  Label\n",
      "473  0.064093  0.594764  312      1\n",
      "113  0.192660  0.062902  302      0\n",
      "266  0.153292  0.077335  305      0\n",
      "31   0.127321  0.110223  300      1\n",
      "623  0.104750  0.122515  321      1\n",
      "         NMF1      NMF2  PID  Label\n",
      "580  0.199230  0.052566  320      0\n",
      "310  0.184635  0.056117  305      0\n",
      "14   0.103687  0.147105  300      1\n",
      "542  0.157105  0.092977  320      0\n",
      "76   0.244976  0.000000  301      0\n"
     ]
    }
   ],
   "source": [
    "#Shuffling after computing the NMF and before feeding into the models \n",
    "NMF_2D_W_train = shuffle(NMF_2D_W_train, random_state = 0)\n",
    "print (NMF_2D_W_train.head())\n",
    "NMF_2D_W_test = shuffle(NMF_2D_W_test, random_state = 0)\n",
    "print (NMF_2D_W_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749, 2) (749, 2)\n",
      "(670, 2) (670, 2)\n"
     ]
    }
   ],
   "source": [
    "#Defining the dataframes to be fed into the models \n",
    "NMF_2D_W_trainX = NMF_2D_W_train.drop(['Label', 'PID'], axis = 1)\n",
    "NMF_2D_W_trainY = NMF_2D_W_train[['PID', 'Label']]\n",
    "print (NMF_2D_W_trainX.shape, NMF_2D_W_trainY.shape)\n",
    "\n",
    "NMF_2D_W_testX = NMF_2D_W_test.drop(['Label', 'PID'], axis = 1)\n",
    "NMF_2D_W_testY = NMF_2D_W_test[['PID', 'Label']]\n",
    "print (NMF_2D_W_testX.shape, NMF_2D_W_testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm\n",
      "Stride-based model performance:  0.9283582089552239 0.9052631578947369 0.8514851485148515 0.8775510204081632 0.9663673098079038\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=3, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Person-based model performance:  1.0 1.0 1.0 1.0 1.0\n",
      "********************************\n",
      "xgboost\n",
      "Stride-based model performance:  0.9253731343283582 0.9 0.8465346534653465 0.8724489795918368 0.9783415841584158\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=1.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Person-based model performance:  1.0 1.0 1.0 1.0 1.0\n",
      "********************************\n",
      "knn\n",
      "Stride-based model performance:  0.9104477611940298 0.9080459770114943 0.7821782178217822 0.8404255319148937 0.9437304307353812\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "                     weights='uniform')\n",
      "Person-based model performance:  0.9411764705882353 1.0 0.875 0.9333333333333333 1.0\n",
      "********************************\n",
      "decision_tree\n",
      "Stride-based model performance:  0.908955223880597 0.9075144508670521 0.7772277227722773 0.8373333333333334 0.9334856562579333\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=34,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=0, splitter='best')\n",
      "Person-based model performance:  0.9411764705882353 1.0 0.875 0.9333333333333333 1.0\n",
      "********************************\n",
      "linear_svm\n",
      "Stride-based model performance:  0.917910447761194 0.9454545454545454 0.7722772277227723 0.8501362397820164 0.9864601844799865\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "          verbose=0)\n",
      "Person-based model performance:  0.8823529411764706 1.0 0.75 0.8571428571428571 1.0\n",
      "********************************\n",
      "logistic_regression\n",
      "Stride-based model performance:  0.8731343283582089 1.0 0.5792079207920792 0.7335423197492162 0.9868621477532369\n",
      "Person-based model performance:  0.7647058823529411 1.0 0.5 0.6666666666666666 1.0\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "ml_models = ['gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression'] #'random_forest', 'adaboost', 'kernel_svm', '\n",
    "# regressN_metrics = pd.DataFrame(columns = ml_models) #Dataframe to store accuracies for each ML model for raw data \n",
    "#For storing predicted probabilities for person (for class 1) to show ROC curves \n",
    "# predicted_probs_person_regressN = pd.DataFrame(columns = ml_models) \n",
    "\n",
    "for ml_model in ml_models:\n",
    "    print (ml_model)\n",
    "    predict_probs_person, stride_person_metrics = models(NMF_2D_W_trainX, NMF_2D_W_trainY, NMF_2D_W_testX, NMF_2D_W_testY, ml_model)\n",
    "    regressN_metrics[ml_model] = stride_person_metrics\n",
    "    predicted_probs_person_regressN[ml_model] = predict_probs_person\n",
    "    print ('********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp\n",
      "Stride-based model performance:  0.9149253731343283 0.9865771812080537 0.7277227722772277 0.8376068376068376 0.9726347634763477\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(50, 50, 50, 50, 50, 20, 30, 100, 60),\n",
      "              learning_rate='adaptive', learning_rate_init=0.001, max_fun=15000,\n",
      "              max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
      "              nesterovs_momentum=True, power_t=0.5, random_state=0,\n",
      "              shuffle=False, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=False)\n",
      "Person-based model performance:  0.8823529411764706 1.0 0.75 0.8571428571428571 1.0\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "#MLP on regress-N \n",
    "ml_models = ['mlp']\n",
    "\n",
    "for ml_model in ml_models:\n",
    "    print (ml_model)\n",
    "    predict_probs_person, stride_person_metrics = models(regressN_trainX_norm, regressN_trainY, regressN_testX_norm, regressN_testY, ml_model)\n",
    "    regressN_metrics[ml_model] = stride_person_metrics\n",
    "    predicted_probs_person_regressN[ml_model] = predict_probs_person.values\n",
    "    print ('********************************')\n",
    "\n",
    "    \n",
    "regressN_metrics.index = ['stride_accuracy', 'stride_precision', 'stride_recall', 'stride_F1', 'stride_AUC', 'person_accuracy', \n",
    "                     'person_precision', 'person_recall', 'person_F1', 'person_AUC']  \n",
    "regressN_metrics.to_csv(path+'..//EDSSprediction//trial_generalize_regressN_2NMFfeatures.csv')\n",
    "predicted_probs_person_regressN.to_csv(path+'..//EDSSprediction//trial_generalize_ROC_regressN_2NMFfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>kernel_svm</th>\n",
       "      <th>gbm</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>knn</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>linear_svm</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stride_accuracy</th>\n",
       "      <td>0.923881</td>\n",
       "      <td>0.926866</td>\n",
       "      <td>0.913433</td>\n",
       "      <td>0.928358</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.908955</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>0.873134</td>\n",
       "      <td>0.914925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_precision</th>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.900524</td>\n",
       "      <td>0.904494</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.908046</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_recall</th>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.797030</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.846535</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.579208</td>\n",
       "      <td>0.727723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_F1</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.875318</td>\n",
       "      <td>0.847368</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.872449</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.837333</td>\n",
       "      <td>0.850136</td>\n",
       "      <td>0.733542</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_AUC</th>\n",
       "      <td>0.976401</td>\n",
       "      <td>0.912843</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>0.966367</td>\n",
       "      <td>0.978342</td>\n",
       "      <td>0.943730</td>\n",
       "      <td>0.933486</td>\n",
       "      <td>0.986460</td>\n",
       "      <td>0.986862</td>\n",
       "      <td>0.972635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_accuracy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_AUC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  random_forest  adaboost  kernel_svm       gbm   xgboost  \\\n",
       "stride_accuracy        0.923881  0.926866    0.913433  0.928358  0.925373   \n",
       "stride_precision       0.899471  0.900524    0.904494  0.905263  0.900000   \n",
       "stride_recall          0.841584  0.851485    0.797030  0.851485  0.846535   \n",
       "stride_F1              0.869565  0.875318    0.847368  0.877551  0.872449   \n",
       "stride_AUC             0.976401  0.912843    0.985297  0.966367  0.978342   \n",
       "person_accuracy        1.000000  1.000000    0.941176  1.000000  1.000000   \n",
       "person_precision       1.000000  1.000000    1.000000  1.000000  1.000000   \n",
       "person_recall          1.000000  1.000000    0.875000  1.000000  1.000000   \n",
       "person_F1              1.000000  1.000000    0.933333  1.000000  1.000000   \n",
       "person_AUC             1.000000  1.000000    1.000000  1.000000  1.000000   \n",
       "\n",
       "                       knn  decision_tree  linear_svm  logistic_regression  \\\n",
       "stride_accuracy   0.910448       0.908955    0.917910             0.873134   \n",
       "stride_precision  0.908046       0.907514    0.945455             1.000000   \n",
       "stride_recall     0.782178       0.777228    0.772277             0.579208   \n",
       "stride_F1         0.840426       0.837333    0.850136             0.733542   \n",
       "stride_AUC        0.943730       0.933486    0.986460             0.986862   \n",
       "person_accuracy   0.941176       0.941176    0.882353             0.764706   \n",
       "person_precision  1.000000       1.000000    1.000000             1.000000   \n",
       "person_recall     0.875000       0.875000    0.750000             0.500000   \n",
       "person_F1         0.933333       0.933333    0.857143             0.666667   \n",
       "person_AUC        1.000000       1.000000    1.000000             1.000000   \n",
       "\n",
       "                       mlp  \n",
       "stride_accuracy   0.914925  \n",
       "stride_precision  0.986577  \n",
       "stride_recall     0.727723  \n",
       "stride_F1         0.837607  \n",
       "stride_AUC        0.972635  \n",
       "person_accuracy   0.882353  \n",
       "person_precision  1.000000  \n",
       "person_recall     0.750000  \n",
       "person_F1         0.857143  \n",
       "person_AUC        1.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressN_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressN_metrics = pd.read_csv(path+'..//EDSSprediction//trial_generalize_regressN_2NMFfeatures.csv')\n",
    "predicted_probs_person_regressN= pd.read_csv(path+'..//EDSSprediction//trial_generalize_ROC_regressN_2NMFfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressN_metrics.index = regressN_metrics['Unnamed: 0']\n",
    "regressN_metrics.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 374.4x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_models = ['random_forest',  'kernel_svm',  'xgboost', 'gbm', 'mlp', 'adaboost', 'linear_svm', 'decision_tree', 'logistic_regression',] \n",
    "#'knn', \n",
    "ml_model_names = {'random_forest': 'RF', 'adaboost': 'Adaboost', 'kernel_svm': 'RBF SVM', 'gbm': 'GBM', \\\n",
    "                  'xgboost': 'Xgboost', 'knn': 'KNN', 'decision_tree': 'DT',  'linear_svm': 'LSVM', \n",
    "             'logistic_regression': 'LR', 'mlp': 'MLP'}\n",
    "person_true_labels = regressN_testY.groupby('PID').first()\n",
    "neutral = [0 for _ in range(len(person_true_labels))] # ROC for majority class prediction all the time \n",
    "\n",
    "fig, axes = plt.subplots(1, 1, sharex=True, sharey = True, figsize=(5.2, 3.5))\n",
    "sns.despine(offset=0)\n",
    "neutral_fpr, neutral_tpr, _ = roc_curve(person_true_labels, neutral) #roc curves\n",
    "\n",
    "linestyles = ['-', '-', '-', '-.', '--', '-', '--', '-', '--']\n",
    "colors = ['b', 'magenta', 'cyan', 'g',  'red', 'violet', 'lime', 'grey', 'pink']\n",
    "\n",
    "#RegressN Data \n",
    "axes.plot(neutral_fpr, neutral_tpr, linestyle='--', label='Majority (AUC = 0.5)', linewidth = 3, color = 'k')\n",
    "for idx, ml_model in enumerate(ml_models):\n",
    "    model_probs = predicted_probs_person_regressN[ml_model] # person-based prediction probabilities\n",
    "    fpr, tpr, _ = roc_curve(person_true_labels, model_probs)\n",
    "    axes.plot(fpr, tpr, label=ml_model_names[ml_model]+' (AUC = '+ str(round(regressN_metrics.loc['person_AUC'][ml_model], 3))\n",
    "                 +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[idx], color = colors[idx])\n",
    "axes.set_ylabel('True Positive Rate')\n",
    "axes.set_title('Cross-task generalization: Regress-N data')\n",
    "plt.legend()\n",
    "# axes[1].legend(loc='upper center', bbox_to_anchor=(1.27, 1), ncol=1)\n",
    "\n",
    "axes.set_xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + '..//EDSSprediction//ROC_task_generalize_regressN_2NMFfeatures.png', dpi = 350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject generalization\n",
    "#### Now, we need to first normalize between 0 and 1 and then fit and tranform using an NMF to get 2 features which we shuffle and then use the ones in training and ones in testing. Note that we cannot normalize or do NMF on training set and testing set separately because, the resultant vectors from train and test NMFs will have different directions (due to unequal variance). Due to this, we’ll end up comparing data registered on different axes. Therefore, the resulting vectors from train and test data should have same axes.\n",
    "##### Refer https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/\n",
    "#### Also, we cannot not combine the train and test set to obtain NMF components of whole data at once. Because, this would violate the entire assumption of generalization since test data would get 'leaked' into the training set. In other words, the test data set would no longer remain 'unseen'. Eventually, this will hammer down the generalization capability of the model.\n",
    "### Hence, we derive the normalization parameters on the training set and then use the same parameters to normalize the test set. Similarly, for NMF, we fit the 2D NMF on training set and then tranform using the fitted NMF both the training and the test set. This way, neither we fit NMF on both training and test set separately nor do we mix them and then do NMF together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true,y_pred):\n",
    "    global yoriginal, ypredicted\n",
    "    yoriginal.append(y_true)\n",
    "    ypredicted.append(y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, yoriginal_, ypredicted_):\n",
    "    best_index = model.cv_results_['mean_test_accuracy'].argmax()\n",
    "    print('best_params: ', model.cv_results_['params'][best_index])\n",
    "\n",
    "    #Stride-wise metrics \n",
    "    stride_metrics_mean, stride_metrics_std = [], [] #Mean and SD of stride based metrics - Acc, P, R, F1, AUC (in order)\n",
    "    scores={'accuracy': make_scorer(acc), 'precision':'precision', 'recall':'recall', 'f1': 'f1', 'auc': 'roc_auc'}\n",
    "    for score in scores:\n",
    "        stride_metrics_mean.append(model.cv_results_['mean_test_'+score][best_index])\n",
    "        stride_metrics_std.append(model.cv_results_['std_test_'+score][best_index])\n",
    "    print('Stride-based model performance (mean): ', stride_metrics_mean)\n",
    "    print('Stride-based model performance (standard deviation): ', stride_metrics_std)\n",
    "    n_folds = 5\n",
    "    person_acc, person_p, person_r, person_f1, person_auc = [], [], [], [], []\n",
    "    #For ROC curves \n",
    "    tpr_list = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        #For each fold, there are 2 splits: test and train (in order) and we need to retrieve the index \n",
    "        #of only test set for required 5 folds (best index)\n",
    "        temp = test_features.loc[yoriginal_[(best_index*n_folds) + (i)].index] #True labels for the test strides in each fold\n",
    "        temp['pred'] = ypredicted_[(best_index*n_folds) + (i)] #Predicted labels for the strides in the test set in each fold\n",
    "\n",
    "        #Correctly classified strides i.e. 1 if stride is correctly classified and 0 if otherwise\n",
    "        temp['correct'] = (temp['Label']==temp['pred'])\n",
    "\n",
    "        #Proportion of correctly classified strides\n",
    "        proportion_strides_correct = temp.groupby('PID').aggregate({'correct': 'mean'})  \n",
    "\n",
    "        proportion_strides_correct['True Label'] = temp[['PID', 'Label']].groupby('PID').first() \n",
    "\n",
    "        #Label for the person - 0=healthy, 1=MS patient\n",
    "        proportion_strides_correct['Predicted Label'] = proportion_strides_correct['True Label']*\\\n",
    "        (proportion_strides_correct['correct']>0.5)+(1-proportion_strides_correct['True Label'])*\\\n",
    "        (proportion_strides_correct['correct']<0.5) \n",
    "\n",
    "        #Probability of class 1 - MS patient for AUC calculation\n",
    "        proportion_strides_correct['prob_class1'] = (1-proportion_strides_correct['True Label'])*\\\n",
    "        (1-proportion_strides_correct['correct'])+ proportion_strides_correct['True Label']*proportion_strides_correct['correct'] \n",
    "\n",
    "        fpr, tpr, _ = roc_curve(proportion_strides_correct['True Label'], proportion_strides_correct['prob_class1'])\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        tpr_list.append(tpr)\n",
    "\n",
    "        #Person wise metrics for each fold \n",
    "        person_acc.append(accuracy_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label']))\n",
    "        person_p.append(precision_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label']))\n",
    "        person_r.append(recall_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label']))\n",
    "        person_f1.append(f1_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label']))\n",
    "        person_auc.append(roc_auc_score(proportion_strides_correct['True Label'], proportion_strides_correct['prob_class1']))\n",
    "\n",
    "    #Mean and standard deviation for person-based metrics \n",
    "    person_means = [np.mean(person_acc), np.mean(person_p), np.mean(person_r), np.mean(person_f1), np.mean(person_auc)]\n",
    "    person_stds = [np.std(person_acc), np.std(person_p), np.std(person_r), np.std(person_f1), np.std(person_auc)]\n",
    "    print('Person-based model performance (mean): ', person_means)\n",
    "    print('Person-based model performance (standard deviation): ', person_stds)\n",
    "\n",
    "    return tpr_list, [stride_metrics_mean, stride_metrics_std, person_means, person_stds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_negatives(X):\n",
    "#     global index_retained \n",
    "    X[X<0] = 0\n",
    "    return X\n",
    "#     newX = X[X>0].dropna()\n",
    "#     index_retained = newX.index\n",
    "#     newY = Y.loc[index_retained]\n",
    "#     return newX, newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not use LDA/QDA since our features are not normally distributed \n",
    "def models(X, Y, model_name = 'random_forest'):\n",
    "    '''\n",
    "    X, Y, PID groups so that strides of each person are either in training or in testing set\n",
    "    model: model_name\n",
    "    '''\n",
    "    Y_ = Y['Label'] #Dropping the PID\n",
    "    groups_ = Y['PID']\n",
    "    gkf = GroupKFold(n_splits=5) \n",
    "    scores={'accuracy': make_scorer(acc), 'precision':'precision', 'recall':'recall', 'f1': 'f1', 'auc': 'roc_auc'}\n",
    "    \n",
    "    if(model_name == 'random_forest'): #Random Forest\n",
    "        grid = {\n",
    "       'randomforestclassifier__n_estimators': [40,45,50],\\\n",
    "       'randomforestclassifier__max_depth' : [15,20,25,None],\\\n",
    "       'randomforestclassifier__class_weight': [None, 'balanced'],\\\n",
    "       'randomforestclassifier__max_features': ['auto','sqrt','log2', None],\\\n",
    "       'randomforestclassifier__min_samples_leaf':[1,2,0.1,0.05]\n",
    "        }\n",
    "        #For z-score scaling on training and use calculated coefficients on test set\n",
    "        rf_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                RandomForestClassifier(random_state=0)) #FunctionTransformer(drop_negatives)\n",
    "        grid_search = GridSearchCV(rf_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'adaboost'): #Adaboost\n",
    "        ada_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 AdaBoostClassifier(random_state=0))\n",
    "        grid = {\n",
    "        'adaboostclassifier__n_estimators':[50, 75, 100, 125, 150],\\\n",
    "        'adaboostclassifier__learning_rate':[0.01,.1, 1, 1.5, 2]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(ada_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "        \n",
    "    if(model_name == 'kernel_svm'): #RBF SVM\n",
    "        svc_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 SVC(kernel = 'rbf', probability=True, random_state=0))\n",
    "        grid = {\n",
    "        'svc__gamma':[0.0001, 0.001, 0.1, 1, 10, ]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(svc_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "\n",
    "    if(model_name == 'gbm'): #GBM\n",
    "        gbm_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 GradientBoostingClassifier(random_state=0))\n",
    "        grid = {\n",
    "        'gradientboostingclassifier__learning_rate':[0.15,0.1,0.05], \\\n",
    "        'gradientboostingclassifier__n_estimators':[50, 100, 150],\\\n",
    "        'gradientboostingclassifier__max_depth':[2,4,7],\\\n",
    "        'gradientboostingclassifier__min_samples_split':[2,4], \\\n",
    "        'gradientboostingclassifier__min_samples_leaf':[1,3],\\\n",
    "        'gradientboostingclassifier__max_features':['auto','sqrt','log2', None],\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(gbm_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name=='xgboost'): #Xgboost\n",
    "        xgb_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 xgboost.XGBClassifier(random_state=0))\n",
    "        grid = {\n",
    "            'xgbclassifier__min_child_weight': [1, 5],\\\n",
    "            'xgbclassifier__gamma': [0.1, 0.5, 1, 1.5, 2],\\\n",
    "            'xgbclassifier__subsample': [0.6, 0.8, 1.0],\\\n",
    "            'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],\\\n",
    "            'xgbclassifier__max_depth': [5, 7, 8]\n",
    "        }\n",
    "        grid_search = GridSearchCV(xgb_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'knn'): #KNN\n",
    "        knn_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 KNeighborsClassifier())\n",
    "        grid = {\n",
    "            'kneighborsclassifier__n_neighbors': [1, 3, 4, 5, 10],\\\n",
    "            'kneighborsclassifier__p': [1, 2, 3, 4, 5]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(knn_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "        \n",
    "    if(model_name == 'decision_tree'): #Decision Tree\n",
    "        dec_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 DecisionTreeClassifier(random_state=0))\n",
    "        #For z-score scaling on training and use calculated coefficients on test set\n",
    "        grid = {'decisiontreeclassifier__min_samples_split': range(2, 50)}\n",
    "        grid_search = GridSearchCV(dec_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "\n",
    "    if(model_name == 'linear_svm'): #Linear SVM\n",
    "        lsvm_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                  LinearSVC(random_state=0))\n",
    "        grid = {\n",
    "            'linearsvc__loss': ['hinge','squared_hinge'],\\\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(lsvm_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'logistic_regression'): #Logistic regression\n",
    "        lr_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                LogisticRegression())\n",
    "        grid = {\n",
    "            'logisticregression__random_state': [0]}\n",
    "            \n",
    "        grid_search = GridSearchCV(lr_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'mlp'):\n",
    "        mlp_grid = make_pipeline(MinMaxScaler(),  FunctionTransformer(drop_negatives),\n",
    "                                decomposition.NMF(n_components=2, init='nndsvda', max_iter=500),\n",
    "                                 MLPClassifier(activation='relu', solver='adam', learning_rate = 'adaptive', learning_rate_init=0.001,\\\n",
    "                                                        shuffle=False, max_iter = 200, random_state = 0))\n",
    "        grid = {\n",
    "        'mlpclassifier__hidden_layer_sizes': [(128, 8, 8, 128, 32), (50, 50, 50, 50, 50, 50, 150, 100, 10), \n",
    "                                  (50, 50, 50, 50, 50, 60, 30, 20, 50), (50, 50, 50, 50, 50, 150, 10, 60, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 50, 10, 5), (50, 50, 50, 50, 50, 5, 50, 150, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 30, 50, 20), (50, 50, 50, 50, 10, 150, 20, 20, 30),\n",
    "                                  (50, 50, 50, 50, 30, 150, 100, 20, 100), (50, 50, 50, 50, 30, 5, 100, 20, 100),\n",
    "                                  (50, 50, 50, 50, 60, 50, 50, 60, 60), (50, 50, 50, 50, 20, 50, 60, 20, 20),\n",
    "                                  (50, 50, 50, 10, 50, 10, 150, 60, 150), (50, 50, 50, 10, 50, 150, 30, 150, 5),\n",
    "                                  (50, 50, 50, 10, 50, 20, 150, 5, 10), (50, 50, 50, 10, 150, 50, 20, 20, 100), \n",
    "                                  (50, 50, 50, 30, 100, 5, 30, 150, 30), (50, 50, 50, 50, 100, 150, 100, 200), \n",
    "                                  (50, 50, 50, 5, 5, 100, 100, 150), (50, 50, 5, 50, 200, 100, 150, 5), \n",
    "                                  (50, 50, 5, 5, 200, 100, 50, 30), (50, 50, 5, 10, 5, 200, 200, 10), \n",
    "                                  (50, 50, 5, 30, 5, 5, 50, 10), (50, 50, 5, 200, 50, 5, 5, 50), \n",
    "                                  (50, 50,50, 5, 5, 100, 100, 150), (5, 5, 5, 5, 5, 100, 50, 5, 50, 50), \n",
    "                                  (5, 5, 5, 5, 5, 100, 20, 100, 30, 30), (5, 5, 5, 5, 5, 20, 20, 5, 30, 100), \n",
    "                                  (5, 5, 5, 5, 5, 20, 20, 100, 10, 10), (5, 5, 5, 5, 10, 10, 30, 50, 10, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 30, 30, 30, 10), (5, 5, 5, 5, 10, 100, 50, 10, 50, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 20, 100, 30, 5), (5, 5, 5, 5, 30, 5, 20, 30, 100, 50), \n",
    "                                  (5, 5, 5, 5, 30, 100, 20, 50, 20, 30), (5, 5, 5, 5, 50, 30, 5, 50, 10, 100), \n",
    "                                  (21, 21, 7, 84, 21, 84, 84), (21, 21, 5, 42, 42, 7, 42), (21, 84, 7, 7, 7, 84, 5), \n",
    "                                  (21, 7, 84, 5, 5, 21, 120), (42, 5, 21, 21, 21, 5, 120), (42, 5, 42, 84, 7, 120, 84), \n",
    "                                  (50, 100, 10, 5, 100, 25), (10, 10, 25, 50, 25, 5), (50, 50, 50, 50, 50, 20, 30, 100, 60)]\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(mlp_grid, param_grid=grid, scoring=scores\\\n",
    "                                    , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "\n",
    "    grid_search.fit(X, Y_, groups=groups_) #Fitting on the training set to find the optimal hyperparameters \n",
    "#     print (len(yoriginal), len(ypredicted))\n",
    "    tpr_list, stride_person_metrics = evaluate(grid_search, Y, yoriginal, ypredicted)\n",
    "    return tpr_list, stride_person_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV for people generalize so no train-test split\n",
    "X_regressN = regressN_df.drop(['Label', 'PID', 'TrialID', 'edss'], axis = 1)\n",
    "Y_regressN = regressN_df[['PID', 'Label']] #PID to compute person based metrics later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157.6"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_regressN.shape[0]*4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost\n",
      "best_params:  {'adaboostclassifier__learning_rate': 0.1, 'adaboostclassifier__n_estimators': 50}\n",
      "Stride-based model performance (mean):  [0.9256919573338817, 0.8581619806603904, 0.8758547993032011, 0.865184550845726, 0.9687409334354935]\n",
      "Stride-based model performance (standard deviation):  [0.034859731337386866, 0.07536834255686949, 0.098505749741479, 0.077684735026498, 0.022838859150136132]\n",
      "Person-based model performance (mean):  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "********************************\n",
      "kernel_svm\n",
      "best_params:  {'svc__gamma': 1}\n",
      "Stride-based model performance (mean):  [0.9220663713263333, 0.9280768429633144, 0.7946839191606316, 0.8488035594216973, 0.9824830255037224]\n",
      "Stride-based model performance (standard deviation):  [0.041693969795545814, 0.03792511691084906, 0.1517880471015139, 0.09141396760854377, 0.00972890347232857]\n",
      "Person-based model performance (mean):  [0.95, 0.9, 1.0, 0.9333333333333332, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.09999999999999999, 0.20000000000000004, 0.0, 0.13333333333333336, 0.0]\n",
      "********************************\n",
      "gbm\n",
      "best_params:  {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 2, 'gradientboostingclassifier__max_features': 'sqrt', 'gradientboostingclassifier__min_samples_leaf': 3, 'gradientboostingclassifier__min_samples_split': 2, 'gradientboostingclassifier__n_estimators': 50}\n",
      "Stride-based model performance (mean):  [0.9191182705749064, 0.8382745582014085, 0.880178932104766, 0.8555761454167863, 0.9759093742636118]\n",
      "Stride-based model performance (standard deviation):  [0.03051415936246997, 0.08843943182454077, 0.09484294823360698, 0.07461869966332513, 0.011550666067113927]\n",
      "Person-based model performance (mean):  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "********************************\n",
      "xgboost\n",
      "best_params:  {'xgbclassifier__colsample_bytree': 0.6, 'xgbclassifier__gamma': 1, 'xgbclassifier__max_depth': 5, 'xgbclassifier__min_child_weight': 1, 'xgbclassifier__subsample': 1.0}\n",
      "Stride-based model performance (mean):  [0.9227741964475975, 0.8494409738254453, 0.8764067464214497, 0.8594995857865821, 0.9761292714740961]\n",
      "Stride-based model performance (standard deviation):  [0.0284929855433545, 0.07505848491349598, 0.09986126078839352, 0.07024366230501647, 0.011051887527333876]\n",
      "Person-based model performance (mean):  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "********************************\n",
      "knn\n",
      "best_params:  {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__p': 1}\n",
      "Stride-based model performance (mean):  [0.8975881639661079, 0.8405253107590369, 0.7771757067570768, 0.7983521365438296, 0.9602854689025946]\n",
      "Stride-based model performance (standard deviation):  [0.04575031216584009, 0.0901879612396385, 0.17373471139676303, 0.11422648385669257, 0.027552069035278143]\n",
      "Person-based model performance (mean):  [0.9, 0.8, 1.0, 0.8666666666666666, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.1224744871391589, 0.2449489742783178, 0.0, 0.16329931618554522, 0.0]\n",
      "********************************\n",
      "decision_tree\n",
      "best_params:  {'decisiontreeclassifier__min_samples_split': 17}\n",
      "Stride-based model performance (mean):  [0.8575813106787546, 0.811906335884448, 0.7041650531072567, 0.747491748905013, 0.8764757797003633]\n",
      "Stride-based model performance (standard deviation):  [0.04196182777077216, 0.08682018038751961, 0.14410202674046071, 0.09359557927911928, 0.07479898083540923]\n",
      "Person-based model performance (mean):  [0.9, 0.8, 1.0, 0.8666666666666666, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.1224744871391589, 0.2449489742783178, 0.0, 0.16329931618554522, 0.0]\n",
      "********************************\n",
      "linear_svm\n",
      "best_params:  {'linearsvc__loss': 'squared_hinge'}\n",
      "Stride-based model performance (mean):  [0.921320190394864, 0.916819080890542, 0.8037533181991374, 0.8504673441383422, 0.9824240571329828]\n",
      "Stride-based model performance (standard deviation):  [0.04065035925879686, 0.038603986152176036, 0.14391340568553262, 0.08815975605918351, 0.009728223736120634]\n",
      "Person-based model performance (mean):  [0.95, 0.9, 1.0, 0.9333333333333332, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.09999999999999999, 0.20000000000000004, 0.0, 0.13333333333333336, 0.0]\n",
      "********************************\n",
      "logistic_regression\n",
      "best_params:  {'logisticregression__random_state': 0}\n",
      "Stride-based model performance (mean):  [0.8539053691034939, 0.9926490713587487, 0.47606844321694586, 0.610532196542778, 0.9827560601413694]\n",
      "Stride-based model performance (standard deviation):  [0.04778427025824124, 0.011744923968724563, 0.23483919416754068, 0.20551271976115465, 0.009658295102010281]\n",
      "Person-based model performance (mean):  [0.8333333333333333, 0.6, 0.8, 0.6666666666666666, 0.9]\n",
      "Person-based model performance (standard deviation):  [0.13944333775567927, 0.37416573867739417, 0.4, 0.36514837167011077, 0.1224744871391589]\n",
      "********************************\n",
      "mlp\n",
      "best_params:  {'mlpclassifier__hidden_layer_sizes': (50, 50, 5, 30, 5, 5, 50, 10)}\n",
      "Stride-based model performance (mean):  [0.9324808338961704, 0.8337218975756574, 0.9314498933901918, 0.8775084997740589, 0.9675829403403837]\n",
      "Stride-based model performance (standard deviation):  [0.040288697038299036, 0.09496738602666407, 0.08407966206881562, 0.07867991175353531, 0.014996452738392155]\n",
      "Person-based model performance (mean):  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Person-based model performance (standard deviation):  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "# regressN_metrics = pd.DataFrame(columns = ml_models) #Dataframe to store accuracies for each ML model for raw data \n",
    "#For storing predicted probabilities for person (for class 1) to show ROC curves \n",
    "# tprs_regressN = pd.DataFrame(columns = ml_models) \n",
    "\n",
    "for ml_model in ml_models[1:]:\n",
    "    print (ml_model)\n",
    "    yoriginal = []\n",
    "    ypredicted = []\n",
    "    tprs, stride_person_metrics = models(X_regressN, Y_regressN, ml_model)\n",
    "    regressN_metrics[ml_model] = sum(stride_person_metrics, [])\n",
    "    tprs_regressN[ml_model] = tprs\n",
    "    print ('********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressN_metrics.index = ['stride_mean_accuracy', 'stride_mean_precision', 'stride_mean_recall', 'stride_mean_F1', \\\n",
    "                     'stride_mean_AUC', 'stride_std_accuracy', 'stride_std_precision', 'stride_std_recall', 'stride_std_F1', \\\n",
    "                     'stride_std_AUC','person_mean_accuracy', 'person_mean_precision', 'person_mean_recall', 'person_mean_F1',\\\n",
    "                     'person_mean_AUC', 'person_std_accuracy', 'person_std_precision', 'person_std_recall', 'person_std_F1',\\\n",
    "                     'person_std_AUC']  \n",
    "regressN_metrics.to_csv(path+'..//EDSSprediction//subject_generalize_regressN_2NMFfeatures.csv')\n",
    "tprs_regressN.to_csv(path+'..//EDSSprediction//subject_generalize_ROCresults_regressN_2NMFfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_forest</th>\n",
       "      <th>adaboost</th>\n",
       "      <th>kernel_svm</th>\n",
       "      <th>gbm</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>knn</th>\n",
       "      <th>decision_tree</th>\n",
       "      <th>linear_svm</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stride_mean_accuracy</th>\n",
       "      <td>0.929315</td>\n",
       "      <td>0.925692</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.922774</td>\n",
       "      <td>0.897588</td>\n",
       "      <td>0.857581</td>\n",
       "      <td>0.921320</td>\n",
       "      <td>0.853905</td>\n",
       "      <td>0.932481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_mean_precision</th>\n",
       "      <td>0.834094</td>\n",
       "      <td>0.858162</td>\n",
       "      <td>0.928077</td>\n",
       "      <td>0.838275</td>\n",
       "      <td>0.849441</td>\n",
       "      <td>0.840525</td>\n",
       "      <td>0.811906</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.992649</td>\n",
       "      <td>0.833722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_mean_recall</th>\n",
       "      <td>0.920149</td>\n",
       "      <td>0.875855</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.880179</td>\n",
       "      <td>0.876407</td>\n",
       "      <td>0.777176</td>\n",
       "      <td>0.704165</td>\n",
       "      <td>0.803753</td>\n",
       "      <td>0.476068</td>\n",
       "      <td>0.931450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_mean_F1</th>\n",
       "      <td>0.871948</td>\n",
       "      <td>0.865185</td>\n",
       "      <td>0.848804</td>\n",
       "      <td>0.855576</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>0.798352</td>\n",
       "      <td>0.747492</td>\n",
       "      <td>0.850467</td>\n",
       "      <td>0.610532</td>\n",
       "      <td>0.877508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_mean_AUC</th>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.968741</td>\n",
       "      <td>0.982483</td>\n",
       "      <td>0.975909</td>\n",
       "      <td>0.976129</td>\n",
       "      <td>0.960285</td>\n",
       "      <td>0.876476</td>\n",
       "      <td>0.982424</td>\n",
       "      <td>0.982756</td>\n",
       "      <td>0.967583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_std_accuracy</th>\n",
       "      <td>0.037777</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.030514</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.045750</td>\n",
       "      <td>0.041962</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>0.040289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_std_precision</th>\n",
       "      <td>0.082205</td>\n",
       "      <td>0.075368</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>0.075058</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>0.086820</td>\n",
       "      <td>0.038604</td>\n",
       "      <td>0.011745</td>\n",
       "      <td>0.094967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_std_recall</th>\n",
       "      <td>0.102855</td>\n",
       "      <td>0.098506</td>\n",
       "      <td>0.151788</td>\n",
       "      <td>0.094843</td>\n",
       "      <td>0.099861</td>\n",
       "      <td>0.173735</td>\n",
       "      <td>0.144102</td>\n",
       "      <td>0.143913</td>\n",
       "      <td>0.234839</td>\n",
       "      <td>0.084080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_std_F1</th>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.077685</td>\n",
       "      <td>0.091414</td>\n",
       "      <td>0.074619</td>\n",
       "      <td>0.070244</td>\n",
       "      <td>0.114226</td>\n",
       "      <td>0.093596</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.205513</td>\n",
       "      <td>0.078680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride_std_AUC</th>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.009729</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.027552</td>\n",
       "      <td>0.074799</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>0.014996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_mean_accuracy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_mean_precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_mean_recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_mean_F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_mean_AUC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_std_accuracy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.139443</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_std_precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_std_recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_std_F1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163299</td>\n",
       "      <td>0.163299</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_std_AUC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       random_forest  adaboost  kernel_svm       gbm  \\\n",
       "stride_mean_accuracy        0.929315  0.925692    0.922066  0.919118   \n",
       "stride_mean_precision       0.834094  0.858162    0.928077  0.838275   \n",
       "stride_mean_recall          0.920149  0.875855    0.794684  0.880179   \n",
       "stride_mean_F1              0.871948  0.865185    0.848804  0.855576   \n",
       "stride_mean_AUC             0.981087  0.968741    0.982483  0.975909   \n",
       "stride_std_accuracy         0.037777  0.034860    0.041694  0.030514   \n",
       "stride_std_precision        0.082205  0.075368    0.037925  0.088439   \n",
       "stride_std_recall           0.102855  0.098506    0.151788  0.094843   \n",
       "stride_std_F1               0.077650  0.077685    0.091414  0.074619   \n",
       "stride_std_AUC              0.007048  0.022839    0.009729  0.011551   \n",
       "person_mean_accuracy        1.000000  1.000000    0.950000  1.000000   \n",
       "person_mean_precision       1.000000  1.000000    0.900000  1.000000   \n",
       "person_mean_recall          1.000000  1.000000    1.000000  1.000000   \n",
       "person_mean_F1              1.000000  1.000000    0.933333  1.000000   \n",
       "person_mean_AUC             1.000000  1.000000    1.000000  1.000000   \n",
       "person_std_accuracy         0.000000  0.000000    0.100000  0.000000   \n",
       "person_std_precision        0.000000  0.000000    0.200000  0.000000   \n",
       "person_std_recall           0.000000  0.000000    0.000000  0.000000   \n",
       "person_std_F1               0.000000  0.000000    0.133333  0.000000   \n",
       "person_std_AUC              0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "                        xgboost       knn  decision_tree  linear_svm  \\\n",
       "stride_mean_accuracy   0.922774  0.897588       0.857581    0.921320   \n",
       "stride_mean_precision  0.849441  0.840525       0.811906    0.916819   \n",
       "stride_mean_recall     0.876407  0.777176       0.704165    0.803753   \n",
       "stride_mean_F1         0.859500  0.798352       0.747492    0.850467   \n",
       "stride_mean_AUC        0.976129  0.960285       0.876476    0.982424   \n",
       "stride_std_accuracy    0.028493  0.045750       0.041962    0.040650   \n",
       "stride_std_precision   0.075058  0.090188       0.086820    0.038604   \n",
       "stride_std_recall      0.099861  0.173735       0.144102    0.143913   \n",
       "stride_std_F1          0.070244  0.114226       0.093596    0.088160   \n",
       "stride_std_AUC         0.011052  0.027552       0.074799    0.009728   \n",
       "person_mean_accuracy   1.000000  0.900000       0.900000    0.950000   \n",
       "person_mean_precision  1.000000  0.800000       0.800000    0.900000   \n",
       "person_mean_recall     1.000000  1.000000       1.000000    1.000000   \n",
       "person_mean_F1         1.000000  0.866667       0.866667    0.933333   \n",
       "person_mean_AUC        1.000000  1.000000       1.000000    1.000000   \n",
       "person_std_accuracy    0.000000  0.122474       0.122474    0.100000   \n",
       "person_std_precision   0.000000  0.244949       0.244949    0.200000   \n",
       "person_std_recall      0.000000  0.000000       0.000000    0.000000   \n",
       "person_std_F1          0.000000  0.163299       0.163299    0.133333   \n",
       "person_std_AUC         0.000000  0.000000       0.000000    0.000000   \n",
       "\n",
       "                       logistic_regression       mlp  \n",
       "stride_mean_accuracy              0.853905  0.932481  \n",
       "stride_mean_precision             0.992649  0.833722  \n",
       "stride_mean_recall                0.476068  0.931450  \n",
       "stride_mean_F1                    0.610532  0.877508  \n",
       "stride_mean_AUC                   0.982756  0.967583  \n",
       "stride_std_accuracy               0.047784  0.040289  \n",
       "stride_std_precision              0.011745  0.094967  \n",
       "stride_std_recall                 0.234839  0.084080  \n",
       "stride_std_F1                     0.205513  0.078680  \n",
       "stride_std_AUC                    0.009658  0.014996  \n",
       "person_mean_accuracy              0.833333  1.000000  \n",
       "person_mean_precision             0.600000  1.000000  \n",
       "person_mean_recall                0.800000  1.000000  \n",
       "person_mean_F1                    0.666667  1.000000  \n",
       "person_mean_AUC                   0.900000  1.000000  \n",
       "person_std_accuracy               0.139443  0.000000  \n",
       "person_std_precision              0.374166  0.000000  \n",
       "person_std_recall                 0.400000  0.000000  \n",
       "person_std_F1                     0.365148  0.000000  \n",
       "person_std_AUC                    0.122474  0.000000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressN_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressN_metrics = pd.read_csv(path+'..//EDSSprediction//subject_generalize_regressN_2NMFfeatures.csv')\n",
    "regressN_metrics.index = regressN_metrics['Unnamed: 0']\n",
    "regressN_metrics.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprs_regressN = pd.read_csv(path+'..//EDSSprediction//subject_generalize_ROCresults_regressN_2NMFfeatures.csv')\n",
    "tprs_regressN.index = tprs_regressN['Unnamed: 0']\n",
    "tprs_regressN.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models1 = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression']\n",
    "\n",
    "for model in ml_models1:\n",
    "    for idx in range(7):\n",
    "#         print (model, idx)\n",
    "        tprs_regressN[model][idx] = np.array(list(map(float, tprs_regressN[model][idx][1:-1].split())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 374.4x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_fpr = np.linspace(0, 1, 101)\n",
    "ml_models = ['random_forest', 'adaboost', 'gbm', 'decision_tree', 'mlp', 'kernel_svm',  'xgboost', \\\n",
    "            'linear_svm', 'logistic_regression'] #'knn'\n",
    "ml_model_names = {'random_forest': 'RF', 'adaboost': 'AdaBoost', 'kernel_svm': 'RBF SVM', 'gbm': 'GBM', \\\n",
    "                  'xgboost': 'Xgboost', 'knn': 'KNN', 'decision_tree': 'DT',  'linear_svm': 'LSVM', \n",
    "             'logistic_regression': 'LR', 'mlp':'MLP'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, sharex=True, sharey = True, figsize=(5.2, 3.5))\n",
    "sns.despine(offset=0)\n",
    "\n",
    "linestyles = ['-', '-', '-', '-.', '--', '-', '--', '-', '--']\n",
    "colors = ['b', 'magenta', 'cyan', 'g',  'red', 'violet', 'lime', 'grey', 'pink']\n",
    "\n",
    "#RegressN Data \n",
    "axes.plot([0, 1], [0, 1], linestyle='--', label='Majority (AUC = 0.5)', linewidth = 3, color = 'k')\n",
    "for idx, ml_model in enumerate(ml_models):\n",
    "    tprs = tprs_regressN[ml_model] # person-based prediction probabilities\n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "    std = tprs.std(axis=0)\n",
    "\n",
    "    tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "    tprs_lower = mean_tprs - std\n",
    "#     axes[2].fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "    axes.plot(base_fpr, mean_tprs, label=ml_model_names[ml_model]+' (AUC = '+ str(round(regressN_metrics.loc['person_mean_AUC']\n",
    "                     [ml_model], 2)) + r'$\\pm$' + str(round(regressN_metrics.loc['person_std_AUC']\n",
    "                     [ml_model], 2)) + ')', linewidth = 3, alpha = 0.8, linestyle = linestyles[idx], color = colors[idx])\n",
    "axes.set_ylabel('True Positive Rate')\n",
    "axes.set_title('RegressN data')\n",
    "axes.legend() #loc='upper center', bbox_to_anchor=(1.27, 1), ncol=1)\n",
    "\n",
    "axes.set_xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + '..//EDSSprediction//ROC_subject_generalize_regressN_2NMFfeatures.png', dpi = 350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
